## LlamaIndex RAG
- Embedding model is running in a RunPod pod
- LLM model is running in another RunPod pod
- ChromaDB is installed locally

### To Do
- Use serverless ChromaDB
- Automate the Model Inference Nodes