{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8939b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U langchain langchain_openai langchain_core langgraph langfuse dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bb24d",
   "metadata": {},
   "source": [
    "## Langfuse Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63837379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils import setup_langfuse_tracer\n",
    "from my_config import MyConfig\n",
    "\n",
    "langfuse_handler = setup_langfuse_tracer()\n",
    "my_config = MyConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39a713",
   "metadata": {},
   "source": [
    "## OpenAI Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Please setp your own key.\n",
    "os.environ[\"OPENAI_API_KEY\"] = my_config.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94605e",
   "metadata": {},
   "source": [
    "## Get the LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6dd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "vision_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "#.achat, .achatstream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5fcbe",
   "metadata": {},
   "source": [
    "## Define the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d289dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def extract_text(img_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from an image file using a multimodal model.\n",
    "\n",
    "    Args:\n",
    "        img_path: A local image file path (strings).\n",
    "\n",
    "    Returns:\n",
    "        A single string containing the concatenated text extracted from each image.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "    try:\n",
    "\n",
    "        # Read image and encode as base64\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            image_bytes = image_file.read()\n",
    "\n",
    "        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "        # Prepare the prompt including the base64 image data\n",
    "        message = [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"Extract all the text from this image. \"\n",
    "                            \"Return only the extracted text, no explanations.\"\n",
    "                        ),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{image_base64}\"\n",
    "                        },\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Call the vision-capable model\n",
    "        response = vision_llm.invoke(message, config={\"langfuse_handler\": langfuse_handler})\n",
    "\n",
    "        # Append extracted text\n",
    "        all_text += response.content + \"\\n\\n\"\n",
    "\n",
    "        return all_text.strip()\n",
    "    except Exception as e:\n",
    "        # You can choose whether to raise or just return an empty string / error message\n",
    "        error_msg = f\"Error extracting text: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "def sum(a: int, b: int) -> float:\n",
    "    \"\"\"Sum a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> float:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def substract(a: int, b: int) -> float:\n",
    "    \"\"\"Substract a and b.\"\"\"\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d609755",
   "metadata": {},
   "source": [
    "## Bind tools to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fe9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    divide,\n",
    "    sum,\n",
    "    multiply,\n",
    "    substract,\n",
    "    extract_text\n",
    "]\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d047",
   "metadata": {},
   "source": [
    "## Defining Agent's State\n",
    "This state is a little more complex than the previous ones we have seen. AnyMessage is a class from Langchain that defines messages, and add_messages is an operator that adds the latest message rather than overwriting it with the latest state.\n",
    "\n",
    "This is a new concept in LangGraph, where you can add operators in your state to define the way they should interact together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc170de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The document provided\n",
    "    input_file: Optional[str]  # Contains file path (PDF/PNG)\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542ff84",
   "metadata": {},
   "source": [
    "## The nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f760376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    # System message\n",
    "    textual_description_of_tool=\"\"\"\n",
    "extract_text(img_path: str) -> str:\n",
    "    Extract text from an image file using a multimodal model.\n",
    "\n",
    "    Args:\n",
    "        img_path: A local image file path (strings).\n",
    "\n",
    "    Returns:\n",
    "        A single string containing the concatenated text extracted from each image.\n",
    "\n",
    "divide(a: int, b: int) -> float:\n",
    "    Divide a and b\n",
    "    Args:\n",
    "        a: The numerator (int).\n",
    "        b: The denominator (int).\n",
    "    Returns:\n",
    "        The result of the division (float).\n",
    "\"\"\"\n",
    "    image=state[\"input_file\"]\n",
    "    sys_msg = SystemMessage(content=f\"You are a helpful butler named Alfred that serves Mr. Wayne and Batman. You can analyse documents and run computations with provided tools:\\n{textual_description_of_tool} \\n You have access to some optional images. Currently the loaded image is: {image}\")\n",
    "\n",
    "    response = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"input_file\": state[\"input_file\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce9aa9",
   "metadata": {},
   "source": [
    "## The ReAct Pattern: How I Assist Mr. Wayne\n",
    "Allow me to explain the approach in this agent. The agent follows what’s known as the ReAct pattern (Reason-Act-Observe)\n",
    "\n",
    "1. **Reason** about his documents and requests\n",
    "2. **Act** by using appropriate tools\n",
    "3. **Observe** the results\n",
    "4. **Repeat** as necessary until I’ve fully addressed his needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c132dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# The graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message requires a tool, route to tools\n",
    "    # Otherwise, provide a direct response\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show the butler's thought process\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714b8af",
   "metadata": {},
   "source": [
    "We define a tools node with our list of tools. The assistant node is just our model with bound tools. We create a graph with assistant and tools nodes.\n",
    "\n",
    "We add a tools_condition edge, which routes to End or to tools based on whether the assistant calls a tool.\n",
    "\n",
    "Now, we add one new step:\n",
    "\n",
    "We connect the tools node back to the assistant, forming a loop.\n",
    "\n",
    "- After the assistant node executes, tools_condition checks if the model’s output is a tool call.\n",
    "- If it is a tool call, the flow is directed to the tools node.\n",
    "- The tools node connects back to assistant.\n",
    "- This loop continues as long as the model decides to call tools.\n",
    "- If the model response is not a tool call, the flow is directed to END, terminating the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7c3b8",
   "metadata": {},
   "source": [
    "## The Butler in Action\n",
    "### Example 1: Simple Calculations\n",
    "\n",
    "Here is an example to show a simple use case of an agent using a tool in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05559cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_xL5nVaQhW9ph6ffEY5cHaEp4', 'function': {'arguments': '{\"a\":20,\"b\":10}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 324, 'total_tokens': 341, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm8wVRFIPzMLYNJrIkIELcOpzYvv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ef78811c-2e42-4fe0-a6fb-e17442fb1ae5-0' tool_calls=[{'name': 'multiply', 'args': {'a': 20, 'b': 10}, 'id': 'call_xL5nVaQhW9ph6ffEY5cHaEp4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 324, 'output_tokens': 17, 'total_tokens': 341, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_aFRf9NAuFTcZy7tMDlaUZrW5', 'function': {'arguments': '{\"a\":87,\"b\":100}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 349, 'total_tokens': 366, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm8xbfj4LrZVVaaKBODM03HUsMMq', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--5e8953d8-db4c-4bc5-9c53-e24409b7d3ce-0' tool_calls=[{'name': 'multiply', 'args': {'a': 87, 'b': 100}, 'id': 'call_aFRf9NAuFTcZy7tMDlaUZrW5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 349, 'output_tokens': 17, 'total_tokens': 366, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_sax64OiAbfTgb7Xdjo9BhYlt', 'function': {'arguments': '{\"a\":8700,\"b\":50}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 375, 'total_tokens': 393, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm8zzyAepNfT5IATjvSbHLYtiiQr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--98580eaa-2884-4ab1-bfbc-705d8687208e-0' tool_calls=[{'name': 'divide', 'args': {'a': 8700, 'b': 50}, 'id': 'call_sax64OiAbfTgb7Xdjo9BhYlt', 'type': 'tool_call'}] usage_metadata={'input_tokens': 375, 'output_tokens': 18, 'total_tokens': 393, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_T0PREALLxgwAvbfXe32U9Fhj', 'function': {'arguments': '{\"a\":200,\"b\":174}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 403, 'total_tokens': 420, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm9074Bo5y8WGSXdsSATMwuA9eJx', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--1b9525cb-4ca9-4e8e-8ad4-65071b6d06b2-0' tool_calls=[{'name': 'sum', 'args': {'a': 200, 'b': 174}, 'id': 'call_T0PREALLxgwAvbfXe32U9Fhj', 'type': 'tool_call'}] usage_metadata={'input_tokens': 403, 'output_tokens': 17, 'total_tokens': 420, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content=\"The evaluated value of the given solution is 374. Let's assign this value to variable A. A = 374.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 428, 'total_tokens': 453, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm910sjNcuYMmzmpZE6zL6HlqglH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--61ee72df-13e0-405b-8683-5b7af956b0be-0' usage_metadata={'input_tokens': 428, 'output_tokens': 25, 'total_tokens': 453, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Assign evaluated value of given solution to variable A: ((20 * 10) + (87 * 100) / 50)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_xL5nVaQhW9ph6ffEY5cHaEp4)\n",
      " Call ID: call_xL5nVaQhW9ph6ffEY5cHaEp4\n",
      "  Args:\n",
      "    a: 20\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "200\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_aFRf9NAuFTcZy7tMDlaUZrW5)\n",
      " Call ID: call_aFRf9NAuFTcZy7tMDlaUZrW5\n",
      "  Args:\n",
      "    a: 87\n",
      "    b: 100\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "8700\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (call_sax64OiAbfTgb7Xdjo9BhYlt)\n",
      " Call ID: call_sax64OiAbfTgb7Xdjo9BhYlt\n",
      "  Args:\n",
      "    a: 8700\n",
      "    b: 50\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "174.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sum (call_T0PREALLxgwAvbfXe32U9Fhj)\n",
      " Call ID: call_T0PREALLxgwAvbfXe32U9Fhj\n",
      "  Args:\n",
      "    a: 200\n",
      "    b: 174\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sum\n",
      "\n",
      "374\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The evaluated value of the given solution is 374. Let's assign this value to variable A. A = 374.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Assign evaluated value of given solution to variable A: ((20 * 10) + (87 * 100) / 50)\")]\n",
    "messages = react_graph.invoke(\n",
    "    {\n",
    "        \"messages\": messages\n",
    "        , \"input_file\": None\n",
    "    }\n",
    "    , config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "# Show the messages\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19cb3690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_n5ZKrRuleaUpBgbGBomPzQQ2', 'function': {'arguments': '{\"a\":8700,\"b\":100}', 'name': 'divide'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 487, 'total_tokens': 505, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm9VXF74Cuawr6HUCR2qe2DdnCv6', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--0641247d-8546-4ec8-9993-5df7174494d1-0' tool_calls=[{'name': 'divide', 'args': {'a': 8700, 'b': 100}, 'id': 'call_n5ZKrRuleaUpBgbGBomPzQQ2', 'type': 'tool_call'}] usage_metadata={'input_tokens': 487, 'output_tokens': 18, 'total_tokens': 505, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_sXJT5cnWiV7YpGczVnNepJUj', 'function': {'arguments': '{\"a\":200,\"b\":87}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 515, 'total_tokens': 532, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm9XUJQwMJKGRIa27TDYFw3TwnY8', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--a305e4d7-505d-4258-8384-2fdd8485f134-0' tool_calls=[{'name': 'sum', 'args': {'a': 200, 'b': 87}, 'id': 'call_sXJT5cnWiV7YpGczVnNepJUj', 'type': 'tool_call'}] usage_metadata={'input_tokens': 515, 'output_tokens': 17, 'total_tokens': 532, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content=\"The evaluated value of the given solution is 287. Let's assign this value to variable B. B = 287.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 540, 'total_tokens': 565, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm9Yscmzkp7MlwnAkESzKxatkbrq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a733026a-a861-4903-89d3-77b67afa3a61-0' usage_metadata={'input_tokens': 540, 'output_tokens': 25, 'total_tokens': 565, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "messages = react_graph.invoke({\n",
    "        \"messages\": reduce(\n",
    "            lambda left, right: add_messages(left, right)\n",
    "            , messages['messages']\n",
    "                + [HumanMessage(content=\"Assign evaluated value of given solution to variable B: ((20 * 10) + (87 * 100) / 100)\")])\n",
    "        , \"input_file\": None\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aa00c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_wrqgK9iLIAxyxLGKlsdMrNUE', 'function': {'arguments': '{\"a\":374,\"b\":287}', 'name': 'sum'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 577, 'total_tokens': 594, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm9pDrblKuUmpxzEWccnwe8Ts1QH', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--d49f3d50-d0c1-4322-bb0d-4c4352bd7bbc-0' tool_calls=[{'name': 'sum', 'args': {'a': 374, 'b': 287}, 'id': 'call_wrqgK9iLIAxyxLGKlsdMrNUE', 'type': 'tool_call'}] usage_metadata={'input_tokens': 577, 'output_tokens': 17, 'total_tokens': 594, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='The sum of A and B is 661.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 602, 'total_tokens': 613, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bmm9qE3W542EMYAkfXWCcO9EDeKm6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--9494b88b-97ca-4a96-9a0c-e08029834f92-0' usage_metadata={'input_tokens': 602, 'output_tokens': 11, 'total_tokens': 613, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "messages = react_graph.invoke({\n",
    "        \"messages\": reduce(\n",
    "            lambda left, right: add_messages(left, right)\n",
    "            , messages['messages']\n",
    "                + [HumanMessage(content=\"What is A + B\")])\n",
    "        , \"input_file\": None\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7a2d3",
   "metadata": {},
   "source": [
    "### Example 2: Analyzing Master Wayne’s Training Documents\n",
    "When Master Wayne leaves his training and meal notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f34eb12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_VTMbGY8ZtGbHVyoQin9S8A4P', 'function': {'arguments': '{\"img_path\":\"data/Batman_training_and_meals.png\"}', 'name': 'extract_text'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 332, 'total_tokens': 355, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BmmCimr2IsLxVykpBFNRHihex8RET', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--f794688b-2f48-4f90-8caf-1f4beefb1250-0' tool_calls=[{'name': 'extract_text', 'args': {'img_path': 'data/Batman_training_and_meals.png'}, 'id': 'call_VTMbGY8ZtGbHVyoQin9S8A4P', 'type': 'tool_call'}] usage_metadata={'input_tokens': 332, 'output_tokens': 23, 'total_tokens': 355, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='The list of items for the dinner menu is as follows:\\n\\n- Grass-fed local sirloin steak\\n- Bed of organic spinach and piquillo peppers\\n- Oven-baked golden herb potato\\n- 2 grams fish oil\\n\\nPlease ensure that these ingredients are purchased for the dinner preparations.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 1096, 'total_tokens': 1155, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BmmDHwWcfA1hLbqcpSXcwHV3OxMyH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f3fca92a-345b-474d-bc89-95c3a0879704-0' usage_metadata={'input_tokens': 1096, 'output_tokens': 59, 'total_tokens': 1155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  extract_text (call_VTMbGY8ZtGbHVyoQin9S8A4P)\n",
      " Call ID: call_VTMbGY8ZtGbHVyoQin9S8A4P\n",
      "  Args:\n",
      "    img_path: data/Batman_training_and_meals.png\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: extract_text\n",
      "\n",
      "TRAINING SCHEDULE  \n",
      "For the week of 2/20-2/26  \n",
      "\n",
      "SUNDAY 2/20  \n",
      "\n",
      "MORNING  \n",
      "30 minute jog  \n",
      "30 minute meditation  \n",
      "\n",
      "EVENING  \n",
      "clean and jerk lifts—3 reps/8 sets, 262 lbs.  \n",
      "5 sets metabolic conditioning:  \n",
      "2 min kettle run  \n",
      "12 kettleball swings  \n",
      "12 pull-ups  \n",
      "30 minutes flexibility  \n",
      "30 minutes sparring  \n",
      "\n",
      "MONDAY 2/21  \n",
      "\n",
      "MORNING  \n",
      "30 minute jog  \n",
      "30 minutes traditional kata (focus on Japanese forms)  \n",
      "\n",
      "EVENING  \n",
      "5 sets 20 foot rope climb  \n",
      "3 minutes gymnastics rings (work on muscle ups in particular)  \n",
      "high box jump—12 reps/8 sets  \n",
      "crunches—50 reps/5 sets  \n",
      "30 minutes heavy bag  \n",
      "30 minutes flexibility  \n",
      "30 minutes target practice  \n",
      "\n",
      "TUESDAY 2/22  \n",
      "\n",
      "MORNING  \n",
      "30 minute jog  \n",
      "30 minutes yoga  \n",
      "\n",
      "EVENING  \n",
      "1/4 mile swim  \n",
      "heavy dead lift—5 reps/7 sets, 620 lbs.  \n",
      "sled machine lift—30 reps t. 350 lbs.  \n",
      "30 minutes sparring  \n",
      "\n",
      "WEDNESDAY 2/23  \n",
      "\n",
      "OFF DAY  \n",
      "\n",
      "MORNING  \n",
      "20-mile run—last week's time was 4:50 per mile.  \n",
      "Need to better that time by a half a minute.  \n",
      "\n",
      "EVENING  \n",
      "skill training only  \n",
      "30 minutes meditation  \n",
      "30 minutes boxing basics  \n",
      "30 minutes swordplay basics  \n",
      "30 minutes body weight exercises  \n",
      "30 minutes observation  \n",
      "30 minutes devotion  \n",
      "30 minutes mood and pressure points  \n",
      "\n",
      "THURSDAY 2/24  \n",
      "\n",
      "MORNING  \n",
      "30 minute jog  \n",
      "30 minutes meditation  \n",
      "30 minutes traditional kata  \n",
      "\n",
      "EVENING  \n",
      "squats—5 reps/10 sets, 525 lbs.  \n",
      "1/2 mile swim  \n",
      "30 minutes flexibility  \n",
      "crunches—50 reps/5 sets  \n",
      "\n",
      "FRIDAY 2/25  \n",
      "\n",
      "MORNING  \n",
      "30 minute jog  \n",
      "30 minute meditation  \n",
      "\n",
      "EVENING  \n",
      "clean and jerk lifts—3 reps/8 sets, 262 lbs.  \n",
      "5 sets metabolic conditioning:  \n",
      "2 min kettle run  \n",
      "12 kettlebell swings  \n",
      "21 pull-ups  \n",
      "30 minutes flexibility  \n",
      "30 minutes sparring  \n",
      "\n",
      "SATURDAY 2/26  \n",
      "\n",
      "MORNING  \n",
      "30 minute jog  \n",
      "30 minutes yoga  \n",
      "\n",
      "EVENING  \n",
      "crunches—50 reps/5 sets  \n",
      "squats—5 reps/10 sets, 525 lbs.  \n",
      "push-ups—50 reps/5 sets  \n",
      "30 minutes monkey bars  \n",
      "10 minute pommel horse  \n",
      "10 minutes heavy bag  \n",
      "1/2 mile swim  \n",
      "\n",
      "\n",
      "In an effort to inspire the all-important Dark Knight to take time out of his busy schedule and actually consume a reasonable amount of sustenance, I have taken the liberty of composing a menu for today's scheduled meal. It is my high hope that these elegantly prepared courses will sustain the Jate (if their predecessors racked cold and untouched on a counter could).  \n",
      "- A\n",
      "WAYNE MANOR\n",
      "\n",
      "Tuesday's Menu\n",
      "\n",
      "Breakfast  \n",
      "\n",
      "six poached eggs laid over artichoke bottoms with a sage pesto sauce  \n",
      "thinly sliced baked ham  \n",
      "mixed organic fresh fruit bowl  \n",
      "freshly squeezed orange juice  \n",
      "organic, grass-fed milk  \n",
      "4 grams branched-chain amino acid  \n",
      "2 grams fish oil  \n",
      "\n",
      "Lunch  \n",
      "\n",
      "local salmon with a ginger glaze  \n",
      "organic asparagus with lemon garlic dusting  \n",
      "Asian yam soup with diced onions  \n",
      "2 grams fish oil  \n",
      "\n",
      "Dinner  \n",
      "\n",
      "grass-fed local sirloin steak  \n",
      "bed of organic spinach and piquillo peppers  \n",
      "oven-baked golden herb potato  \n",
      "2 grams fish oil\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The list of items for the dinner menu is as follows:\n",
      "\n",
      "- Grass-fed local sirloin steak\n",
      "- Bed of organic spinach and piquillo peppers\n",
      "- Oven-baked golden herb potato\n",
      "- 2 grams fish oil\n",
      "\n",
      "Please ensure that these ingredients are purchased for the dinner preparations.\n"
     ]
    }
   ],
   "source": [
    "# with open(\"data/Batman_training_and_meals.png\", \"rb\") as img_file:\n",
    "#     img_base64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# messages = [HumanMessage(\n",
    "#     content=[\n",
    "#         {\n",
    "#             \"type\": \"text\",\n",
    "#             \"text\": (\n",
    "#                 \"According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\"\n",
    "#             ),\n",
    "#         },\n",
    "#         {\n",
    "#             \"type\": \"image_url\",\n",
    "#             \"image_url\": {\n",
    "#                 \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "#             },\n",
    "#         },\n",
    "#     ]\n",
    "# )]\n",
    "# messages = react_graph.invoke(\n",
    "#     {\n",
    "#         \"messages\": messages\n",
    "#         , \"input_file\": None\n",
    "#     }\n",
    "#     , config={\"callbacks\": [langfuse_handler]}\n",
    "# )\n",
    "\n",
    "messages = [HumanMessage(content=\"According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\")]\n",
    "response = react_graph.invoke(\n",
    "    {\n",
    "        \"messages\": messages\n",
    "        , \"input_file\": \"data/Batman_training_and_meals.png\"\n",
    "    }\n",
    "    , config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "# Show the messages\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9386378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
