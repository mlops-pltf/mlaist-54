{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd53555",
   "metadata": {},
   "source": [
    "### Setup langfuse tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c319cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils import setup_langfuse_tracer\n",
    "from my_config import MyConfig\n",
    "\n",
    "langfuse_handler = setup_langfuse_tracer()\n",
    "my_config = MyConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f46664",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba72d81",
   "metadata": {},
   "source": [
    "### Create a model from the Ollama model that is running on runpod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04029c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "remote_url = f\"https://{my_config.OLLAMA_INFERENCE_RUNPOD_ID}-11434.proxy.runpod.net\"\n",
    "model = ChatOllama(\n",
    "    base_url=remote_url\n",
    "    # , model='deepseek-r1:32b'\n",
    "    , model='llama4:scout'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152e60ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"What is the capitalof India?\", config={\"callbacks\": [langfuse_handler]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5c529",
   "metadata": {},
   "source": [
    "### LangGraph imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068f6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011999a",
   "metadata": {},
   "source": [
    "### Define Our State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6944c2",
   "metadata": {},
   "source": [
    "##### Let’s define what information Alfred needs to track during the email processing workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445732bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
    "\n",
    "    # Category of the email (inquiry, complaint, etc.)\n",
    "    email_category: Optional[str]\n",
    "\n",
    "    # Email Classification Description\n",
    "    classification_description: Optional[str]\n",
    "\n",
    "    # Email Classification Description\n",
    "    analyze_classification_response: Optional[str]\n",
    "\n",
    "    # Email Classification Result\n",
    "    spam_result: Optional[str]\n",
    "\n",
    "    # Reason why the email was marked as spam\n",
    "    spam_reason: Optional[str]\n",
    "\n",
    "    # Analysis and decisions\n",
    "    is_spam: Optional[bool]\n",
    "    \n",
    "    # Response generation\n",
    "    email_draft: Optional[str]\n",
    "    \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e94aa7",
   "metadata": {},
   "source": [
    "#### Define Our Nodes\n",
    "Now, let’s create the processing functions that will form our nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ab453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email(state: EmailState):\n",
    "    \"\"\"Alfred reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Here we might do some initial preprocessing\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    \n",
    "    # No state changes needed here\n",
    "    return {}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, analyze this email and try to reason about if it is spam or legitimate.\n",
    "    Please provide the classification conclusion and a brief explanation within **classification_conclusion** block.\n",
    "    If it is spam, provide a reason within **spam_reason** block.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    First, determine if this email is spam. If it is spam, explain why.\n",
    "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
    "    response_text = response.content.lower()\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"classification_description\": response_text.lower().split(\"**classification_conclusion**\")[-1].strip().split('**')[0] if \"**classification_conclusion**\" in response_text else response_text,\n",
    "        \"spam_reason\": response_text.lower().split(\"**spam_reason**\")[-1].strip().split('**')[0] if \"**spam_reason**\" in response_text else response_text,\n",
    "        \"messages\": state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_classification(state: EmailState):\n",
    "    \"\"\"Alfred analyzes the classification result and updates state accordingly\"\"\"\n",
    "    classification_output = state[\"classification_description\"]\n",
    "\n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, figure out if the mail is spam or not based on the classification description.\n",
    "    Use the **classification_conclusion** block from the input.\n",
    "    After analysing the output state `spam` or `not spam` in clear CAPITAL letters. Provide this output in **final_classification_result** block\n",
    "\n",
    "    \n",
    "    This is the classification result in detail:\n",
    "        **classification_conclusion**\n",
    "        {classification_output}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    response_text = response.content\n",
    "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
    "    spam_result = response_text.split(\"**final_classification_result**\")[-1].strip() if \"**final_classification_result**\" in response_text else response_text\n",
    "    is_spam = \"SPAM\" in spam_result and \"NOT SPAM\" not in spam_result\n",
    "    spam_reason = state.get(\"spam_reason\", \"No reason provided\")\n",
    "    \n",
    "    # Determine category if legitimate\n",
    "    email_category = None\n",
    "    if not is_spam:\n",
    "        categories = [\"inquiry\", \"complaint\", \"thank you\", \"request\", \"information\"]\n",
    "        for category in categories:\n",
    "            if category in response_text:\n",
    "                email_category = category\n",
    "                break\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": email_category,\n",
    "        \"messages\": new_messages,\n",
    "        \"analyze_classification_response\": response_text,\n",
    "        \"spam_result\": spam_result\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Alfred discards spam email with a note\"\"\"\n",
    "    print(f\"Alfred has marked the email as spam. Reason: {state['spam_reason']}\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    print(f\"Email is marked as spam with reason: {state['spam_reason']}\")\n",
    "\n",
    "    # We're done processing this email\n",
    "    return {}\n",
    "\n",
    "def draft_response(state: EmailState):\n",
    "    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    category = state[\"email_category\"] or \"general\"\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, draft a polite preliminary response to this email.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    This email has been categorized as: {category}\n",
    "    \n",
    "    Draft a brief, professional response that Mr. Hugg can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"email_draft\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_hugg(state: EmailState):\n",
    "    \"\"\"Alfred notifies Mr. Hugg about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Category: {state['email_category']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"email_draft\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d9e12",
   "metadata": {},
   "source": [
    "#### Define Our Routing Logic\n",
    "We need a function to determine which path to take after classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e098d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ed751",
   "metadata": {},
   "source": [
    "#### Create the StateGraph and Define Edges\n",
    "Now we connect everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e6aed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)\n",
    "email_graph.add_node(\"classify_email\", classify_email)\n",
    "email_graph.add_node(\"analyze_classification\", analyze_classification)\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)\n",
    "email_graph.add_node(\"draft_response\", draft_response)\n",
    "email_graph.add_node(\"notify_mr_hugg\", notify_mr_hugg)\n",
    "\n",
    "# Start the edges\n",
    "email_graph.add_edge(START, \"read_email\")\n",
    "# Add edges - defining the flow\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")\n",
    "email_graph.add_edge(\"classify_email\", \"analyze_classification\")\n",
    "\n",
    "# Add conditional branching from classify_email\n",
    "email_graph.add_conditional_edges(\n",
    "    \"analyze_classification\",\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",\n",
    "        \"legitimate\": \"draft_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the final edges\n",
    "email_graph.add_edge(\"handle_spam\", END)\n",
    "email_graph.add_edge(\"draft_response\", \"notify_mr_hugg\")\n",
    "email_graph.add_edge(\"notify_mr_hugg\", END)\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2e140",
   "metadata": {},
   "source": [
    "#### Run the Application\n",
    "Let’s test our graph with a legitimate email and a spam email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea0e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing legitimate email...\n",
      "Alfred is processing an email from john.smith@example.com with subject: Question about your services\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from john.smith@example.com.\n",
      "Subject: Question about your services\n",
      "Category: None\n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Here's a draft response:\n",
      "\n",
      "Dear Mr. Smith,\n",
      "\n",
      "Thank you for reaching out and for the referral from your colleague. I'm pleased to hear that you're interested in learning more about my consulting services.\n",
      "\n",
      "I'd be delighted to schedule a call with you next week. Could you please let me know a few dates and times that work for you, and I'll do my best to accommodate them?\n",
      "\n",
      "I look forward to speaking with you soon.\n",
      "\n",
      "Best regards,\n",
      "Mr. Hugg\n",
      "==================================================\n",
      "\n",
      "\n",
      "Processing spam email...\n",
      "Alfred is processing an email from winner@lottery-intl.com with subject: YOU HAVE WON $5,000,000!!!\n",
      "Alfred has marked the email as spam. Reason: : the email exhibits several red flags commonly associated with spam or phishing attempts:\n",
      "1. \n",
      "The email has been moved to the spam folder.\n",
      "Email is marked as spam with reason: : the email exhibits several red flags commonly associated with spam or phishing attempts:\n",
      "1. \n"
     ]
    }
   ],
   "source": [
    "# Example legitimate email\n",
    "legitimate_email = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
    "}\n",
    "\n",
    "# Example spam email\n",
    "spam_email = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
    "}\n",
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "}, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# Process the spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "}, config={\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe20f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
