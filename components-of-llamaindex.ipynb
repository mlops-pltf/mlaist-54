{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708b5568",
   "metadata": {},
   "source": [
    "## Create a `QueryEngine` for retrieval augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9100bc",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Setting up the persona database\n",
    "We will be using personas from the dvilasuero/finepersonas-v0.1-tiny dataset. This dataset contains 5K personas that will be attending the party!\n",
    "Let's load the dataset and store it as files in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc799279",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_lzma'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdvilasuero/finepersonas-v0.1-tiny\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/arrow_dataset.py:73\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/arrow_reader.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _split_re, filenames_for_dataset_split\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryTable, MemoryMappedTable, Table, concat_tables\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/download/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamingDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadManager, DownloadMode\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_download_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/download/download_manager.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     ArchiveIterable,\n\u001b[1;32m     34\u001b[0m     FilesIterable,\n\u001b[1;32m     35\u001b[0m     cached_path,\n\u001b[1;32m     36\u001b[0m     is_relative_path,\n\u001b[1;32m     37\u001b[0m     stack_multiprocessing_download_progress_bars,\n\u001b[1;32m     38\u001b[0m     url_or_path_join,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_size_checksum_dict\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger, tqdm\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/utils/file_utils.py:44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tqdm, logging\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtractManager\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrackedIterableFromGenerator\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/MLArena/MLOps-Platform-Project/Hands-On/hfagnt-2-2-the-llamaindex-framework/.venv/lib/python3.9/site-packages/datasets/utils/extract.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlzma\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/lib/python3.9/lzma.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _encode_filter_properties, _decode_filter_properties\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_compression\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_lzma'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = load_dataset(path=\"dvilasuero/finepersonas-v0.1-tiny\", split=\"train\")\n",
    "\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "for i, persona in enumerate(dataset):\n",
    "    with open(Path(\"data\") / f\"persona_{i}.txt\", \"w\") as f:\n",
    "        f.write(persona[\"persona\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e818312",
   "metadata": {},
   "source": [
    "### Loading and embedding persona documents\n",
    "We will use the `SimpleDirectoryReader` to load the persona descriptions from the `data` directory. This will return a list of `Document` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf64071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data\")\n",
    "documents = reader.load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c87b79",
   "metadata": {},
   "source": [
    "Now we have a list of `Document` objects, we can use the `IngestionPipeline` to create nodes from the documents and prepare them for the `QueryEngine`.\n",
    "\n",
    "We will use the `SentenceSplitter` to split the documents into smaller chunks and the `HuggingFaceEmbedding` (via `vLLM` possibly) to embed the chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc65c85",
   "metadata": {},
   "source": [
    "#### Create a Custom Embedding Class\n",
    "We are subclassing `BaseEmbedding` from `llama_index` and override the `aget_text_embedding` method to hit my `RunPod` endpoint. Super Cool stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d673b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "import aiohttp\n",
    "from typing import Optional\n",
    "\n",
    "class RunPodEmbedding(BaseEmbedding):\n",
    "    endpoint_url: str  # <-- declare as pydantic field\n",
    "\n",
    "    def __init__(self, endpoint_url: str, **kwargs):\n",
    "        super().__init__(endpoint_url=endpoint_url, **kwargs)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            payload = {\"input\": text}\n",
    "            async with session.post(self.endpoint_url, json=payload) as resp:\n",
    "                result = await resp.json()\n",
    "                return result[\"data\"][0][\"embedding\"]  # <-- Adjusted\n",
    "\n",
    "    def _get_text_embedding(self, text: str):\n",
    "        raise NotImplementedError(\"Sync embedding not implemented.\")\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str):\n",
    "        return await self._aget_text_embedding(query)\n",
    "\n",
    "    def _get_query_embedding(self, query: str):\n",
    "        raise NotImplementedError(\"Sync embedding not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26888b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='e0ffbf3b-2e20-4d4e-b79b-33ff39d3295b', embedding=[0.024533309042453766, 0.07586681097745895, 0.0316290557384491, -0.04244034364819527, -0.022829793393611908, -0.05504904314875603, 0.07951528578996658, 0.02806106209754944, -0.03122664988040924, -0.03868456184864044, -0.023017583414912224, -0.11514157056808472, 0.029992608353495598, 0.01081799529492855, 0.009322389028966427, 0.027873273938894272, -0.012689180672168732, 0.012709300965070724, 0.01733025535941124, 0.012266654521226883, 0.03578724339604378, -0.052393168210983276, -0.012762954458594322, -0.006589386612176895, -0.04147457331418991, 0.007954210974276066, 0.016136452555656433, -0.024090664461255074, -0.024654030799865723, -0.09351898729801178, -0.029885299503803253, 0.006810709368437529, 0.0038094366900622845, 0.015465776436030865, -0.01797410286962986, -0.00606961315497756, 0.0294292401522398, 0.0221993587911129, 0.002328920643776655, 0.09169474989175797, 0.028892699629068375, -0.06164849177002907, 0.01317877322435379, 0.040642935782670975, 0.03407031670212746, -0.06803332269191742, -0.00456394674256444, -0.0037691963370889425, -0.03267531096935272, -0.061058297753334045, -0.07511565834283829, -0.05314432457089424, -0.018859393894672394, -0.03490195423364639, -0.0011359566124156117, 0.004037466365844011, 0.08767069876194, 0.03200463578104973, -0.005707448348402977, 0.036565229296684265, 0.053385768085718155, 0.08949493616819382, -0.14711937308311462, 0.08595377206802368, -0.01812165230512619, 0.06889178603887558, -0.03200463578104973, -0.0684625506401062, -0.0695892870426178, -0.08359299600124359, -0.06411657482385635, 0.025364946573972702, 0.031468093395233154, 0.03672619163990021, 0.03747734799981117, -0.03170953691005707, 0.007464618422091007, -0.006381477229297161, -0.04045514389872551, 0.038067542016506195, 0.042011111974716187, -0.007565219420939684, -0.014406109228730202, -0.03747734799981117, 0.041930630803108215, 0.049093447625637054, 0.010187560692429543, 0.01767900586128235, -0.005747688934206963, 0.0219713281840086, -0.040079567581415176, 0.0007352280081249774, 0.04828863590955734, 0.022977342829108238, -0.008812676183879375, -0.012052038684487343, -0.02126041240990162, 0.06803332269191742, -0.049656812101602554, 0.4004737436771393, -0.015425535850226879, -0.031897325068712234, 0.0577317476272583, 0.027457455173134804, 0.012125812470912933, -0.020723871886730194, 0.03342646732926369, -0.008007865399122238, 0.05113229900598526, -0.02305782400071621, -0.040428318083286285, 0.05397596210241318, -0.054405197501182556, 0.01285684946924448, 0.043298810720443726, 0.033050887286663055, 0.05048844963312149, 0.061272911727428436, -0.031682711094617844, -0.0278464462608099, -0.007531685754656792, -0.04048197343945503, 0.06390196084976196, -0.0022769432980567217, 0.012474563904106617, 0.022145705297589302, 0.025364946573972702, 0.050676241517066956, 0.016498617827892303, 0.03951619938015938, 0.025391774252057076, 0.007350603584200144, -0.03128030523657799, 0.008953518234193325, -0.0013581179082393646, 0.0439426563680172, -0.0035646401811391115, -0.02156892418861389, 0.030421840026974678, -0.012011798098683357, -0.038121193647384644, 0.0002959355479106307, 0.035197049379348755, 0.0502738356590271, -0.08488068729639053, 0.0492544062435627, -0.014956063590943813, 0.03938206657767296, -0.014298801310360432, 0.05751712992787361, -0.04761796072125435, 0.011877662502229214, -0.03382887318730354, -0.020294640213251114, 0.009007171727716923, -0.03114617057144642, 0.09131917357444763, 0.018725259229540825, -0.051454223692417145, -0.025163743644952774, 0.0068006496876478195, -0.09652362018823624, -0.022896861657500267, 0.05842924863100052, 0.013990290462970734, -0.09131917357444763, -0.014459763653576374, -0.004791976418346167, 0.034687336534261703, -0.04018687456846237, 0.06368734687566757, 0.013131826184689999, -0.028919527307152748, 0.03702128678560257, 0.07093063741922379, -0.0012675767065957189, -0.002483176067471504, 0.04659853130578995, -0.0015551288379356265, 0.03007308952510357, 0.017021743580698967, 0.010422296822071075, -0.022574936971068382, -0.010348523035645485, -0.012534924782812595, -0.026451440528035164, -0.059609636664390564, 0.0163242407143116, 0.046008337289094925, -0.022521283477544785, 0.029751164838671684, 0.0822516456246376, -0.006368063855916262, -0.04968364164233208, 0.04152822494506836, -0.004912698175758123, -0.01175023429095745, 0.017947275191545486, -0.0406697615981102, 0.0038094366900622845, -0.02929510548710823, 0.07999817281961441, -0.016512030735611916, 0.02663923054933548, -0.02814154326915741, -0.06572619825601578, 0.0019600491505116224, 0.007766422349959612, 0.011180160567164421, -0.030851071700453758, -0.011743527837097645, -0.011616099625825882, -0.10639595985412598, 0.027551349252462387, 0.011394776403903961, -0.01975809969007969, 0.060629066079854965, -0.013064758852124214, 0.06556523591279984, 0.0006220515351742506, -0.02771231159567833, -0.08530992269515991, -0.0640629231929779, -0.3141980469226837, 0.04584737494587898, -0.018926462158560753, 0.05762443691492081, -0.0074512045830488205, 0.00780666247010231, 0.003366790944710374, 0.019020356237888336, 0.03216559812426567, 0.010771048255264759, -0.007766422349959612, -0.028704911470413208, -0.013856155797839165, 0.0908362865447998, -0.0038027300033718348, 0.021515268832445145, 0.008591352961957455, 0.00018579806783236563, -0.034848298877477646, -0.007954210974276066, 0.0006048654322512448, 0.010348523035645485, -0.0009255321929231286, -0.08740243315696716, 0.017424149438738823, -0.012145932763814926, 0.10532288253307343, 0.07710085064172745, -0.020455602556467056, -0.09695284813642502, 0.028382986783981323, 0.04555227980017662, -0.014204907231032848, -0.13864204287528992, 0.004956291988492012, -0.019731272011995316, 0.06663831323385239, -0.044854775071144104, 0.011441723443567753, 0.015251160599291325, 0.0243455208837986, -0.04539131745696068, 0.007122573908418417, 0.04769844189286232, -0.07731547206640244, 0.03125347942113876, 0.006814063061028719, -0.009905876591801643, 0.044801123440265656, -0.004483465570956469, 0.004255435895174742, 0.02749769575893879, -0.015090198256075382, -0.023755325004458427, -0.09818689525127411, 0.011086265556514263, -0.03482147306203842, -0.030341358855366707, -0.028195196762681007, 0.05628308653831482, 0.034982431679964066, 0.00690795760601759, 0.04241351783275604, -0.001778966747224331, 0.02370167151093483, -0.058751173317432404, -0.050729893147945404, 0.03323867544531822, 0.06207772344350815, -0.019851993769407272, 0.015734046697616577, 0.11310271173715591, -0.07398892194032669, -0.02142137475311756, 0.02757817693054676, -0.005365403834730387, 0.019677618518471718, -0.022440802305936813, 0.01006013248115778, 0.027175771072506905, 0.08321741223335266, -0.06771139800548553, -0.047456998378038406, -0.024949127808213234, 0.019248386844992638, 0.03093155287206173, -0.012695887126028538, -0.04375486820936203, 0.03959668055176735, -0.02356753684580326, 0.00794750452041626, 0.02950972132384777, -0.039569854736328125, 0.005395584274083376, -0.02878539264202118, 0.01747780293226242, -0.260758638381958, 0.059180404990911484, -0.023648018017411232, 0.006163507699966431, 0.07613508403301239, 0.0035109862219542265, -0.03559945523738861, 0.0009959531016647816, 0.02956337481737137, -0.02900000847876072, 0.10119152069091797, 0.016216933727264404, 0.03753099963068962, 0.02792692743241787, 0.012487977743148804, -0.017142465338110924, 0.04713507369160652, 0.006847596727311611, 0.02348705567419529, -0.03331915661692619, -0.026545336470007896, -0.04724238067865372, 0.1367104947566986, 0.016565684229135513, -0.046652186661958694, -0.07200372219085693, -0.0007507373811677098, -0.027014808729290962, 0.0017471096944063902, -0.0715208351612091, 0.021300652995705605, -0.0013053021393716335, 0.04657170549035072, -0.010234507732093334, 0.008819382637739182, 0.0042185490019619465, -0.012454443611204624, -0.0018929815851151943, -0.009443110786378384, -0.03173636272549629, -0.03221924975514412, -0.019851993769407272, 0.041420917958021164, 0.020026370882987976, 0.0736669972538948, -0.009718087501823902, -0.045659586787223816, -0.03986494988203049, 0.02607586234807968, 0.019597137346863747, 0.0432719811797142, -0.043647561222314835, -0.05735616758465767, 0.06036079302430153, 0.007337189745157957, -0.02698798105120659, -0.033399637788534164, -0.047296036034822464, 0.06438484787940979, -0.040213704109191895, -0.006076320074498653, 0.015130438841879368, 0.01590842194855213, -0.047430168837308884, -0.00891327764838934], metadata={'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d6c1375a-9b54-4efc-908c-0be61abc4f45', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, hash='933f06b703857eb8bc9e508970156db877211d3969e3695bf4865eb25c02624d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# Instantiate custom class with your RunPod URL\n",
    "runpod_url = \"https://h8zdxcaagexdrc-8000.proxy.runpod.net/v1/embeddings\"\n",
    "embedding_model = RunPodEmbedding(endpoint_url=runpod_url)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        embedding_model,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run the pipeline (async example)\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "nodes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e12ea1",
   "metadata": {},
   "source": [
    "### Storing and indexing documents\n",
    "Since we are using an ingestion pipeline, we can directly attach a vector store to the pipeline to populate it. In this case, we will use `Chroma` to store our documents. Let's run the pipeline again with the vector store attached. The `IngestionPipeline` caches the operations so this should be fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab5352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "\n",
    "# Instantiate custom class with your RunPod URL\n",
    "runpod_url = \"https://h8zdxcaagexdrc-8000.proxy.runpod.net/v1/embeddings\"\n",
    "embedding_model = RunPodEmbedding(endpoint_url=runpod_url)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        embedding_model\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a074900",
   "metadata": {},
   "source": [
    "We can create a `VectorStoreIndex` from the vector store and use it to query the documents by passing the vector store and embedding model to the `from_vector_store()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237cde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "\n",
    "# Instantiate custom class with your RunPod URL\n",
    "runpod_url = \"https://h8zdxcaagexdrc-8000.proxy.runpod.net/v1/embeddings\"\n",
    "embedding_model = RunPodEmbedding(endpoint_url=runpod_url)\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a8d33",
   "metadata": {},
   "source": [
    "We don't need to worry about persisting the index to disk, as it is automatically saved within the `ChromaVectorStore` object and the passed directory path.\n",
    "\n",
    "### Querying the index\n",
    "Now that we have our index, we can use it to query the documents. Let's create a `QueryEngine` from the index and use it to query the documents using a specific response mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42a30809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "import aiohttp\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "449aba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.llms import ChatMessage, LLMMetadata, CompletionResponse  # Sometimes required\n",
    "import aiohttp\n",
    "from typing import List, Any\n",
    "\n",
    "class RunPodQwenLLM(LLM):\n",
    "    api_url: str  # Pydantic field\n",
    "\n",
    "    def __init__(self, api_url: str, **kwargs):\n",
    "        super().__init__(api_url=api_url, **kwargs)\n",
    "\n",
    "    # 🟢 Async chat: core method for LlamaIndex RAG\n",
    "    async def achat(\n",
    "        self, messages: List[ChatMessage], **kwargs\n",
    "    ) -> str:\n",
    "        # Prepare payload\n",
    "        payload = {\n",
    "            \"model\": \"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "            \"messages\": [\n",
    "                {\"role\": m.role, \"content\": m.content} for m in messages\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(self.api_url, json=payload) as resp:\n",
    "                result = await resp.json()\n",
    "                output_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return ChatMessage(role=\"assistant\", content=output_text)\n",
    "\n",
    "    # 🔴 All other required methods: stub/not implemented\n",
    "    async def astream_chat(self, messages: List[ChatMessage], **kwargs) -> Any:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def astream_complete(self, prompt: str, **kwargs) -> Any:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def chat(self, messages: List[ChatMessage], **kwargs) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def complete(self, prompt: str, **kwargs) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def stream_chat(self, messages: List[ChatMessage], **kwargs) -> Any:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def stream_complete(self, prompt: str, **kwargs) -> Any:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def acomplete(self, prompt: str, **kwargs) -> CompletionResponse:\n",
    "        payload = {\n",
    "            \"model\": \"Qwen/Qwen2.5-Coder-7B-Instruct\",   # Adjust model name as needed\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(self.api_url, json=payload) as resp:\n",
    "                result = await resp.json()\n",
    "                output_text = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return CompletionResponse(\n",
    "                    text=output_text,\n",
    "                    usage=result.get(\"usage\", {}),\n",
    "                    model=self.metadata.model_name\n",
    "                )\n",
    "    \n",
    "    async def _get_query_embedding(self, query: str):\n",
    "        # Simple solution: use asyncio to run async in sync context (not efficient, but unblocks you)\n",
    "        import asyncio\n",
    "        return asyncio.run(self._aget_query_embedding(query))\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        return LLMMetadata(\n",
    "            name=\"RunPodQwenLLM\",\n",
    "            description=\"RunPod Qwen LLM for chat completions\",\n",
    "            model_name=\"Qwen/Qwen2.5-Coder-7B-Instruct\",  # Adjust model name as needed\n",
    "            max_input_size=4096,  # Adjust based on the model's capabilities\n",
    "            max_output_tokens=1024,  # Adjust based on your needs\n",
    "            context_window=2048,  # Adjust based on your needs\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e00a8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_api_base = \"https://e9q6qi5px4g2md-8000.proxy.runpod.net/v1/chat/completions\"\n",
    "llm = RunPodQwenLLM(api_url=vllm_api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94d549bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a230a420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"**Persona:** Dr. Elena Vassiliou, an accomplished anthropologist specializing in Cypriot culture, history, and society. With over two decades of dedicated research and firsthand experience living in Cyprus, Dr. Vassiliou has become an authority on the intricate tapestry of Cypriot life. Her extensive fieldwork has provided her with invaluable insights into the daily customs, traditions, and social dynamics of the island's diverse communities. As a resident of Nicosia for ten years, she has witnessed firsthand how historical events have shaped contemporary Cypriot society and how traditional practices coexist with modern influences. Through her extensive travels across the Mediterranean, Dr. Vassiliou has also gained a broader perspective on regional cultures, enriching her understanding of Cyprus within a wider context. Her work continues to inspire and educate those interested in exploring the rich heritage and evolving identity of Cyprus.\", source_nodes=[NodeWithScore(node=TextNode(id_='8cbfc317-72ff-4cae-a75e-92549d32f408', embedding=None, metadata={'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='655dd596-5f8b-4dea-acf2-da2298f44a0d', node_type='4', metadata={'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, hash='933f06b703857eb8bc9e508970156db877211d3969e3695bf4865eb25c02624d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.508559271837558), NodeWithScore(node=TextNode(id_='27a89989-f379-4ca7-afb8-86407307e362', embedding=None, metadata={'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d6c1375a-9b54-4efc-908c-0be61abc4f45', node_type='4', metadata={'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, hash='933f06b703857eb8bc9e508970156db877211d3969e3695bf4865eb25c02624d')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.508559271837558)], metadata={'8cbfc317-72ff-4cae-a75e-92549d32f408': {'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}, '27a89989-f379-4ca7-afb8-86407307e362': {'file_path': '/home/ec2-user/workspace/hfagnt-2-2-the-llamaindex-framework/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-12', 'last_modified_date': '2025-06-12'}})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"Respond using a persona that describes author and travel experiences?\"\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
